{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edbc4245",
   "metadata": {},
   "source": [
    "# LMD - Simple Autoencoder\n",
    "\n",
    "Demonstrate how an autoencoder remembers input images pixel by pixel.\n",
    "\n",
    "1. Define dimensions of the image and resize input images accordingly\n",
    "2. Train autoencoder. Throughout each step, save a copy of the reconstruction of the image\n",
    "3. Display reconstructed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974b4b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and path relative to project\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '../pyno/lib'))\n",
    "\n",
    "from autoencoder import Autoencoder\n",
    "from abstract_dataset import AbstractDataset\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"CUDA not available\")\n",
    "    \n",
    "# CUDA related information\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION', )\n",
    "from subprocess import call\n",
    "# call([\"nvcc\", \"--version\"]) does not work\n",
    "! nvcc --version\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "# call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d39a0a7",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f05e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image\n",
    "image_height = 800\n",
    "image_width = 800\n",
    "\n",
    "dir_input_images = \"/home/ralampay/Pictures/niece\"\n",
    "dir_output_images = \"/home/ralampay/Pictures/niece-lmd\"\n",
    "\n",
    "# Device for training\n",
    "\n",
    "# The topology of the model from input layer to innermost latent layer\n",
    "input_dim = image_height * image_width\n",
    "hidden_layer_dimension = int(10)\n",
    "\n",
    "layers = [input_dim, hidden_layer_dimension]\n",
    "print(layers)\n",
    "\n",
    "device = 'cuda:0'\n",
    "h_activation = 'relu'\n",
    "o_activation = 'sigmoid'\n",
    "device = torch.device(device)\n",
    "error_type = 'mse'\n",
    "optimizer_type = 'adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f08e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the autoencoder\n",
    "autoencoder = Autoencoder(\n",
    "                layers=layers, \n",
    "                h_activation=h_activation, \n",
    "                o_activation=o_activation, \n",
    "                device=device, \n",
    "                error_type=error_type, \n",
    "                optimizer_type=optimizer_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b027cb1",
   "metadata": {},
   "source": [
    "## Build the Dataset as a vector of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c39790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = ['png', 'jpg', 'gif']    # Add image formats here\n",
    "\n",
    "files = []\n",
    "[files.extend(glob.glob(dir_input_images + '/*.' + e)) for e in ext]\n",
    "\n",
    "dim = (image_width, image_height)\n",
    "\n",
    "images = np.array([cv2.resize(cv2.imread(file, cv2.IMREAD_GRAYSCALE), dim) for file in files])\n",
    "\n",
    "for image in images:\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "input_data = np.array([image.ravel() / 255 for image in images])\n",
    "print(input_data)\n",
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77664766",
   "metadata": {},
   "source": [
    "## Setup Tensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f634c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(input_data).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da168757",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 0.01\n",
    "batch_size = 5\n",
    "\n",
    "data = AbstractDataset(x)\n",
    "dataloader = DataLoader(dataset=data, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "autoencoder.optimizer = optim.Adam(autoencoder.parameters(), lr=lr)\n",
    "\n",
    "num_iterations = data.n_samples / batch_size\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    curr_loss = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        autoencoder.optimizer.zero_grad()\n",
    "        \n",
    "        output = autoencoder.forward(inputs)\n",
    "        \n",
    "        \n",
    "        loss = (output - labels).pow(2).sum(dim=1).sqrt().mean()\n",
    "        \n",
    "        curr_loss += loss\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        autoencoder.optimizer.step()\n",
    "        \n",
    "        # display the images\n",
    "        raw_output = output.detach().cpu().numpy()\n",
    "        \n",
    "        for o in raw_output:\n",
    "            output_image = np.reshape(o * 255, (image_width, image_height))\n",
    "            file_to_write = \"{}/{}.jpg\".format(dir_output_images, str(counter))\n",
    "            print(\"File to write: {}\".format(file_to_write))\n",
    "            cv2.imwrite(file_to_write, output_image)\n",
    "            plt.imshow(output_image)\n",
    "            plt.show()\n",
    "            \n",
    "            counter = counter + 1\n",
    "            \n",
    "    curr_loss = curr_loss / num_iterations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

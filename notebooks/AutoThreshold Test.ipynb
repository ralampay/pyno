{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6464f1bd",
   "metadata": {},
   "source": [
    "# AutoThreshold Test\n",
    "\n",
    "Notebook for testing class `AutoThresholdRe` features namely:\n",
    "\n",
    "1. Passing a pre-trained autoencoder to determine threshold\n",
    "2. Apply classification for anomalous data\n",
    "3. Measure performance\n",
    "\n",
    "In this example, we will be training the `creditcardfraud.csv` with an autoencoder. The `AutoThresholdRe` class will be utilized to determine an automatic threshold to determine anomalous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daaa2a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and path relative to project\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '../pyno/lib'))\n",
    "\n",
    "from autoencoder import Autoencoder\n",
    "from auto_threshold_re import AutoThresholdRe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a86016",
   "metadata": {},
   "source": [
    "## Autoencoder Training\n",
    "\n",
    "Similar to Autoencoder Test, train an autoencoder with topology `[29, 27, 25]` against the credit card dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ae274af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset '../data/creditcardfraud.csv'...\n",
      "Reading chunk 1\n",
      "Reading chunk 2\n",
      "Reading chunk 3\n",
      "Reading chunk 4\n",
      "Reading chunk 5\n",
      "Reading chunk 6\n",
      "Reading chunk 7\n",
      "Reading chunk 8\n",
      "Reading chunk 9\n",
      "Reading chunk 10\n",
      "Reading chunk 11\n",
      "Reading chunk 12\n",
      "Reading chunk 13\n",
      "Reading chunk 14\n",
      "Reading chunk 15\n",
      "Reading chunk 16\n",
      "Reading chunk 17\n",
      "Reading chunk 18\n",
      "Reading chunk 19\n",
      "Reading chunk 20\n",
      "Reading chunk 21\n",
      "Reading chunk 22\n",
      "Reading chunk 23\n",
      "Reading chunk 24\n",
      "Reading chunk 25\n",
      "Reading chunk 26\n",
      "Reading chunk 27\n",
      "Reading chunk 28\n",
      "Reading chunk 29\n",
      "Done loading dataset...\n",
      "Input Dimensionality: 29\n",
      "Epoch: 1\tLoss: 0.59087\n",
      "Epoch: 2\tLoss: 0.22608\n",
      "Epoch: 3\tLoss: 0.21531\n",
      "Epoch: 4\tLoss: 0.21393\n",
      "Epoch: 5\tLoss: 0.21254\n",
      "Epoch: 6\tLoss: 0.21088\n",
      "Epoch: 7\tLoss: 0.20770\n",
      "Epoch: 8\tLoss: 0.20238\n",
      "Epoch: 9\tLoss: 0.19742\n",
      "Epoch: 10\tLoss: 0.19293\n",
      "Epoch: 11\tLoss: 0.18980\n",
      "Epoch: 12\tLoss: 0.18780\n",
      "Epoch: 13\tLoss: 0.18690\n",
      "Epoch: 14\tLoss: 0.18621\n",
      "Epoch: 15\tLoss: 0.18515\n",
      "Epoch: 16\tLoss: 0.18374\n",
      "Epoch: 17\tLoss: 0.18060\n",
      "Epoch: 18\tLoss: 0.17810\n",
      "Epoch: 19\tLoss: 0.17031\n",
      "Epoch: 20\tLoss: 0.16775\n",
      "Epoch: 21\tLoss: 0.16565\n",
      "Epoch: 22\tLoss: 0.16244\n",
      "Epoch: 23\tLoss: 0.15599\n",
      "Epoch: 24\tLoss: 0.15194\n",
      "Epoch: 25\tLoss: 0.15009\n",
      "Epoch: 26\tLoss: 0.14983\n",
      "Epoch: 27\tLoss: 0.14853\n",
      "Epoch: 28\tLoss: 0.14778\n",
      "Epoch: 29\tLoss: 0.14677\n",
      "Epoch: 30\tLoss: 0.14532\n",
      "Epoch: 31\tLoss: 0.14283\n",
      "Epoch: 32\tLoss: 0.14097\n",
      "Epoch: 33\tLoss: 0.13822\n",
      "Epoch: 34\tLoss: 0.13673\n",
      "Epoch: 35\tLoss: 0.13660\n",
      "Epoch: 36\tLoss: 0.13597\n",
      "Epoch: 37\tLoss: 0.13617\n",
      "Epoch: 38\tLoss: 0.13550\n",
      "Epoch: 39\tLoss: 0.13539\n",
      "Epoch: 40\tLoss: 0.13534\n",
      "Epoch: 41\tLoss: 0.13469\n",
      "Epoch: 42\tLoss: 0.13457\n",
      "Epoch: 43\tLoss: 0.13379\n",
      "Epoch: 44\tLoss: 0.13308\n",
      "Epoch: 45\tLoss: 0.13251\n",
      "Epoch: 46\tLoss: 0.13085\n",
      "Epoch: 47\tLoss: 0.12843\n",
      "Epoch: 48\tLoss: 0.12581\n",
      "Epoch: 49\tLoss: 0.12265\n",
      "Epoch: 50\tLoss: 0.12052\n",
      "Epoch: 51\tLoss: 0.11850\n",
      "Epoch: 52\tLoss: 0.11768\n",
      "Epoch: 53\tLoss: 0.11586\n",
      "Epoch: 54\tLoss: 0.11509\n",
      "Epoch: 55\tLoss: 0.11371\n",
      "Epoch: 56\tLoss: 0.11242\n",
      "Epoch: 57\tLoss: 0.11165\n",
      "Epoch: 58\tLoss: 0.11077\n",
      "Epoch: 59\tLoss: 0.11049\n",
      "Epoch: 60\tLoss: 0.10962\n",
      "Epoch: 61\tLoss: 0.10927\n",
      "Epoch: 62\tLoss: 0.10894\n",
      "Epoch: 63\tLoss: 0.10944\n",
      "Epoch: 64\tLoss: 0.10902\n",
      "Epoch: 65\tLoss: 0.10840\n",
      "Epoch: 66\tLoss: 0.10825\n",
      "Epoch: 67\tLoss: 0.10782\n",
      "Epoch: 68\tLoss: 0.10836\n",
      "Epoch: 69\tLoss: 0.10822\n",
      "Epoch: 70\tLoss: 0.10811\n",
      "Epoch: 71\tLoss: 0.10780\n",
      "Epoch: 72\tLoss: 0.10790\n",
      "Epoch: 73\tLoss: 0.10766\n",
      "Epoch: 74\tLoss: 0.10783\n",
      "Epoch: 75\tLoss: 0.10737\n",
      "Epoch: 76\tLoss: 0.10755\n",
      "Epoch: 77\tLoss: 0.10742\n",
      "Epoch: 78\tLoss: 0.10730\n",
      "Epoch: 79\tLoss: 0.10718\n",
      "Epoch: 80\tLoss: 0.10711\n",
      "Epoch: 81\tLoss: 0.10702\n",
      "Epoch: 82\tLoss: 0.10686\n",
      "Epoch: 83\tLoss: 0.10660\n",
      "Epoch: 84\tLoss: 0.10672\n",
      "Epoch: 85\tLoss: 0.10619\n",
      "Epoch: 86\tLoss: 0.10610\n",
      "Epoch: 87\tLoss: 0.10589\n",
      "Epoch: 88\tLoss: 0.10532\n",
      "Epoch: 89\tLoss: 0.10498\n",
      "Epoch: 90\tLoss: 0.10481\n",
      "Epoch: 91\tLoss: 0.10459\n",
      "Epoch: 92\tLoss: 0.10215\n",
      "Epoch: 93\tLoss: 0.10108\n",
      "Epoch: 94\tLoss: 0.10576\n",
      "Epoch: 95\tLoss: 0.09769\n",
      "Epoch: 96\tLoss: 0.09561\n",
      "Epoch: 97\tLoss: 0.09369\n",
      "Epoch: 98\tLoss: 0.09402\n",
      "Epoch: 99\tLoss: 0.09323\n",
      "Epoch: 100\tLoss: 0.09254\n"
     ]
    }
   ],
   "source": [
    "# The topology of the model from input layer to innermost latent layer\n",
    "layers = [29, 27, 25]\n",
    "\n",
    "h_activation = 'relu'\n",
    "o_activation = 'sigmoid'\n",
    "device = torch.device('cpu')\n",
    "error_type = 'mse'\n",
    "optimizer_type = 'adam'\n",
    "\n",
    "# Initialize the autoencoder\n",
    "autoencoder = Autoencoder(\n",
    "                layers=layers, \n",
    "                h_activation=h_activation, \n",
    "                o_activation=o_activation, \n",
    "                device=device, \n",
    "                error_type=error_type, \n",
    "                optimizer_type=optimizer_type)\n",
    "\n",
    "# Instantiate pandas DataFrame\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Chunk size for reading data\n",
    "chunksize = 10000\n",
    "\n",
    "# The reference to the dataset. Change this to \n",
    "dataset_file = '../data/creditcardfraud.csv'\n",
    "\n",
    "print(\"Loading dataset '{}'...\".format(dataset_file))\n",
    "\n",
    "# Read each chunk and append to data frame\n",
    "for i, chunk in enumerate(pd.read_csv(dataset_file, header=None, chunksize=chunksize)):\n",
    "    print(\"Reading chunk %d\" % (i + 1))\n",
    "    data = data.append(chunk)\n",
    "\n",
    "print(\"Done loading dataset...\")\n",
    "    \n",
    "# Check for proper value of input dimensionality to be used by model\n",
    "input_dim = len(data.columns) - 1\n",
    "print(\"Input Dimensionality: %d\" % (input_dim))\n",
    "\n",
    "# Partition the data into positive_data and negative_data\n",
    "positive_data = data[data[input_dim] == 1].iloc[:,:input_dim]\n",
    "negative_data = data[data[input_dim] == -1].iloc[:,:input_dim]\n",
    "\n",
    "# x representing all data regardless of label.\n",
    "# Need to convert it to a tensor before passing it to the model for training\n",
    "x = torch.tensor(positive_data.values).float()\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.005\n",
    "batch_size = 10000\n",
    "\n",
    "autoencoder.fit(\n",
    "    x, \n",
    "    epochs=epochs, \n",
    "    lr=lr,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52655eb6",
   "metadata": {},
   "source": [
    "## AutoThreshold computation\n",
    "\n",
    "Creates an instance of `AutoThresholdRe` and compute based on the initial training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "634cbbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.19802218160861892\n"
     ]
    }
   ],
   "source": [
    "cmd = AutoThresholdRe(x, autoencoder)\n",
    "cmd.execute()\n",
    "\n",
    "print(\"Optimal Threshold: {}\".format(cmd.optimal_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7ee7e3",
   "metadata": {},
   "source": [
    "## Classification with AutoThresholdRe\n",
    "\n",
    "Use the `predict(x)` method of `AutoTresholdRe` to classify data as either normal (`1`) or anomalous (`-1`) using the `optimal_threshold` defined in the class. `x` should be a tensor variable in pytorch while the `predict` returns numpy array.\n",
    "\n",
    "In the code below, we are passing all anomalous data and see if the model can classify it correctly as `-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97e9c9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1  1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1  1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1  1 -1  1 -1 -1 -1  1  1  1 -1 -1  1  1 -1 -1 -1 -1 -1 -1\n",
      " -1  1  1 -1  1 -1 -1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1  1  1\n",
      " -1  1 -1  1 -1 -1 -1  1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1  1 -1 -1\n",
      "  1 -1 -1 -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1  1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1  1 -1  1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1  1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1 -1 -1  1  1  1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1\n",
      " -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1 -1  1 -1\n",
      " -1 -1 -1 -1 -1  1  1 -1 -1 -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1\n",
      " -1 -1 -1 -1  1  1 -1 -1 -1 -1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "outliers = torch.tensor(negative_data.values).float()\n",
    "\n",
    "predictions = cmd.predict(outliers)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6604a32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_199032/125487268.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdiffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "diffs = cmd.predict(x)\n",
    "print(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c4872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
